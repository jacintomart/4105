{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q7kbplJjZMeY",
        "outputId": "7c050e31-bd4a-492b-c9d4-93d222138eb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
              "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
              "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
              "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
              "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
              "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
              "\n",
              "              class  \n",
              "0          dog_bark  \n",
              "1  children_playing  \n",
              "2  children_playing  \n",
              "3  children_playing  \n",
              "4  children_playing  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4926b6c-1982-433d-948a-b63dd8973620\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>slice_file_name</th>\n",
              "      <th>fsID</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>salience</th>\n",
              "      <th>fold</th>\n",
              "      <th>classID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100032-3-0-0.wav</td>\n",
              "      <td>100032</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.317551</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100263-2-0-117.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>58.5</td>\n",
              "      <td>62.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100263-2-0-121.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>60.5</td>\n",
              "      <td>64.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100263-2-0-126.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>63.0</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100263-2-0-137.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>68.5</td>\n",
              "      <td>72.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4926b6c-1982-433d-948a-b63dd8973620')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c4926b6c-1982-433d-948a-b63dd8973620 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c4926b6c-1982-433d-948a-b63dd8973620');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "#download_path = Path.cwd()/'drive/MyDrive/ML/Urban8K'\n",
        "data_path = '/content/drive/MyDrive/ML/Urban8k/'\n",
        "# Read metadata file\n",
        "metadata_file = '/content/drive/MyDrive/ML/Urban8k/UrbanSound8K_changed.csv'\n",
        "df = pd.read_csv(metadata_file)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct file path by concatenating fold and file name\n",
        "df['relative_path'] = '/fold' + df['fold'].astype(str) + '/' + df['slice_file_name'].astype(str)\n",
        "\n",
        "# Take relevant columns\n",
        "df = df[['relative_path', 'classID']]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Giuy5lRvcwfT",
        "outputId": "05d14884-771f-4a7d-a1c5-a1b1ce2fd3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               relative_path  classID\n",
              "0    /fold5/100032-3-0-0.wav        3\n",
              "1  /fold5/100263-2-0-117.wav        2\n",
              "2  /fold5/100263-2-0-121.wav        2\n",
              "3  /fold5/100263-2-0-126.wav        2\n",
              "4  /fold5/100263-2-0-137.wav        2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a09229ff-c8dd-4e99-abaa-29906a6f05bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>relative_path</th>\n",
              "      <th>classID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/fold5/100032-3-0-0.wav</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/fold5/100263-2-0-117.wav</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/fold5/100263-2-0-121.wav</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/fold5/100263-2-0-126.wav</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/fold5/100263-2-0-137.wav</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a09229ff-c8dd-4e99-abaa-29906a6f05bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a09229ff-c8dd-4e99-abaa-29906a6f05bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a09229ff-c8dd-4e99-abaa-29906a6f05bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math, random\n",
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio import transforms\n",
        "from IPython.display import Audio\n",
        "\n",
        "class AudioUtil():\n",
        "  # ----------------------------\n",
        "  # Load an audio file. Return the signal as a tensor and the sample rate\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def open(audio_file):\n",
        "    sig, sr = torchaudio.load(audio_file)\n",
        "    return (sig, sr)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Convert the given audio to the desired number of channels\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def rechannel(aud, new_channel):\n",
        "      sig, sr = aud\n",
        "\n",
        "      if (sig.shape[0] == new_channel):\n",
        "        # Nothing to do\n",
        "        return aud\n",
        "\n",
        "      if (new_channel == 1):\n",
        "        # Convert from stereo to mono by selecting only the first channel\n",
        "        resig = sig[:1, :]\n",
        "      else:\n",
        "        # Convert from mono to stereo by duplicating the first channel\n",
        "        resig = torch.cat([sig, sig])\n",
        "\n",
        "      return ((resig, sr))\n",
        "\n",
        "  # ----------------------------\n",
        "  # Since Resample applies to a single channel, we resample one channel at a time\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def resample(aud, newsr):\n",
        "    sig, sr = aud\n",
        "\n",
        "    if (sr == newsr):\n",
        "      # Nothing to do\n",
        "      return aud\n",
        "\n",
        "    num_channels = sig.shape[0]\n",
        "    # Resample first channel\n",
        "    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
        "    if (num_channels > 1):\n",
        "      # Resample the second channel and merge both channels\n",
        "      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
        "      resig = torch.cat([resig, retwo])\n",
        "\n",
        "    return ((resig, newsr))\n",
        "\n",
        "  # ----------------------------\n",
        "  # Pad (or truncate) the signal to a fixed length 'max_ms' in milliseconds\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def pad_trunc(aud, max_ms):\n",
        "    sig, sr = aud\n",
        "    num_rows, sig_len = sig.shape\n",
        "    max_len = sr//1000 * max_ms\n",
        "\n",
        "    if (sig_len > max_len):\n",
        "      # Truncate the signal to the given length\n",
        "      sig = sig[:,:max_len]\n",
        "\n",
        "    elif (sig_len < max_len):\n",
        "      # Length of padding to add at the beginning and end of the signal\n",
        "      pad_begin_len = random.randint(0, max_len - sig_len)\n",
        "      pad_end_len = max_len - sig_len - pad_begin_len\n",
        "\n",
        "      # Pad with 0s\n",
        "      pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
        "      pad_end = torch.zeros((num_rows, pad_end_len))\n",
        "\n",
        "      sig = torch.cat((pad_begin, sig, pad_end), 1)\n",
        "      \n",
        "    return (sig, sr)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Shifts the signal to the left or right by some percent. Values at the end\n",
        "  # are 'wrapped around' to the start of the transformed signal.\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def time_shift(aud, shift_limit):\n",
        "    sig,sr = aud\n",
        "    _, sig_len = sig.shape\n",
        "    shift_amt = int(random.random() * shift_limit * sig_len)\n",
        "    return (sig.roll(shift_amt), sr)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Generate a Spectrogram\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
        "    sig,sr = aud\n",
        "    top_db = 80\n",
        "\n",
        "    # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
        "    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
        "\n",
        "    # Convert to decibels\n",
        "    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
        "    return (spec)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Augment the Spectrogram by masking out some sections of it in both the frequency\n",
        "  # dimension (ie. horizontal bars) and the time dimension (vertical bars) to prevent\n",
        "  # overfitting and to help the model generalise better. The masked sections are\n",
        "  # replaced with the mean value.\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
        "    _, n_mels, n_steps = spec.shape\n",
        "    mask_value = spec.mean()\n",
        "    aug_spec = spec\n",
        "\n",
        "    freq_mask_param = max_mask_pct * n_mels\n",
        "    for _ in range(n_freq_masks):\n",
        "      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
        "\n",
        "    time_mask_param = max_mask_pct * n_steps\n",
        "    for _ in range(n_time_masks):\n",
        "      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
        "\n",
        "    return aug_spec"
      ],
      "metadata": {
        "id": "09BzK65idlYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchaudio\n",
        "\n",
        "# ----------------------------\n",
        "# Sound Dataset\n",
        "# ----------------------------\n",
        "class SoundDS(Dataset):\n",
        "  def __init__(self, df, data_path):\n",
        "    self.df = df\n",
        "    self.data_path = str(data_path)\n",
        "    self.duration = 4000\n",
        "    self.sr = 44100\n",
        "    self.channel = 2\n",
        "    self.shift_pct = 0.4\n",
        "            \n",
        "  # ----------------------------\n",
        "  # Number of items in dataset\n",
        "  # ----------------------------\n",
        "  def __len__(self):\n",
        "    return len(self.df)    \n",
        "    \n",
        "  # ----------------------------\n",
        "  # Get i'th item in dataset\n",
        "  # ----------------------------\n",
        "  def __getitem__(self, idx):\n",
        "    # Absolute file path of the audio file - concatenate the audio directory with\n",
        "    # the relative path\n",
        "    audio_file = self.data_path + self.df.loc[idx, 'relative_path']\n",
        "    # Get the Class ID\n",
        "    class_id = self.df.loc[idx, 'classID']\n",
        "\n",
        "    aud = AudioUtil.open(audio_file)\n",
        "    # Some sounds have a higher sample rate, or fewer channels compared to the\n",
        "    # majority. So make all sounds have the same number of channels and same \n",
        "    # sample rate. Unless the sample rate is the same, the pad_trunc will still\n",
        "    # result in arrays of different lengths, even though the sound duration is\n",
        "    # the same.\n",
        "    reaud = AudioUtil.resample(aud, self.sr)\n",
        "    rechan = AudioUtil.rechannel(reaud, self.channel)\n",
        "\n",
        "    dur_aud = AudioUtil.pad_trunc(rechan, self.duration)\n",
        "    shift_aud = AudioUtil.time_shift(dur_aud, self.shift_pct)\n",
        "    sgram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
        "    aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
        "\n",
        "    return aug_sgram, class_id"
      ],
      "metadata": {
        "id": "BMJGd1yBli6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "myds = SoundDS(df, data_path)\n",
        "\n",
        "# Random split of 80:20 between training and validation\n",
        "num_items = len(myds)\n",
        "num_train = round(num_items * 0.8)\n",
        "num_val = num_items - num_train\n",
        "train_ds, val_ds = random_split(myds, [num_train, num_val])\n",
        "\n",
        "# Create training and validation data loaders\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "0FIOJClC22lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "import torch.nn as nn\n",
        "\n",
        "# ----------------------------\n",
        "# Audio Classification Model\n",
        "# ----------------------------\n",
        "class AudioClassifier (nn.Module):\n",
        "    # ----------------------------\n",
        "    # Build the model architecture\n",
        "    # ----------------------------\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        conv_layers = []\n",
        "\n",
        "        # First Convolution Block with Relu and Batch Norm. Use Kaiming Initialization\n",
        "        self.conv1 = nn.Conv2d(2, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "        init.kaiming_normal_(self.conv1.weight, a=0.1)\n",
        "        self.conv1.bias.data.zero_()\n",
        "        conv_layers += [self.conv1, self.relu1, self.bn1]\n",
        "\n",
        "        # Second Convolution Block\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "        init.kaiming_normal_(self.conv2.weight, a=0.1)\n",
        "        self.conv2.bias.data.zero_()\n",
        "        conv_layers += [self.conv2, self.relu2, self.bn2]\n",
        "\n",
        "        # Second Convolution Block\n",
        "        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "        init.kaiming_normal_(self.conv3.weight, a=0.1)\n",
        "        self.conv3.bias.data.zero_()\n",
        "        conv_layers += [self.conv3, self.relu3, self.bn3]\n",
        "\n",
        "        # Second Convolution Block\n",
        "        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "        init.kaiming_normal_(self.conv4.weight, a=0.1)\n",
        "        self.conv4.bias.data.zero_()\n",
        "        conv_layers += [self.conv4, self.relu4, self.bn4]\n",
        "\n",
        "        # Linear Classifier\n",
        "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.lin = nn.Linear(in_features=64, out_features=10)\n",
        "\n",
        "        # Wrap the Convolutional Blocks\n",
        "        self.conv = nn.Sequential(*conv_layers)\n",
        " \n",
        "    # ----------------------------\n",
        "    # Forward pass computations\n",
        "    # ----------------------------\n",
        "    def forward(self, x):\n",
        "        # Run the convolutional blocks\n",
        "        x = self.conv(x)\n",
        "\n",
        "        # Adaptive pool and flatten for input to linear layer\n",
        "        x = self.ap(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        # Linear layer\n",
        "        x = self.lin(x)\n",
        "\n",
        "        # Final output\n",
        "        return x\n",
        "\n",
        "# Create the model and put it on the GPU if available\n",
        "myModel = AudioClassifier()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "myModel = myModel.to(device)\n",
        "# Check that it is on Cuda\n",
        "next(myModel.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjv3U0MyJpSU",
        "outputId": "df971e8f-45d0-42a8-fcb6-51ac3e1e4ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "\n",
        "vgg = models.vgg16()\n",
        "summary(vgg, (3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymDzwM3ylv0H",
        "outputId": "9136d46a-eaef-4730-c835-62d9c82c2e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "              ReLU-2         [-1, 64, 224, 224]               0\n",
            "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
            "              ReLU-4         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
            "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
            "              ReLU-7        [-1, 128, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
            "              ReLU-9        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
            "             ReLU-12          [-1, 256, 56, 56]               0\n",
            "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-14          [-1, 256, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-16          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
            "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
            "             ReLU-19          [-1, 512, 28, 28]               0\n",
            "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-21          [-1, 512, 28, 28]               0\n",
            "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-23          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
            "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-26          [-1, 512, 14, 14]               0\n",
            "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-28          [-1, 512, 14, 14]               0\n",
            "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-30          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
            "           Linear-33                 [-1, 4096]     102,764,544\n",
            "             ReLU-34                 [-1, 4096]               0\n",
            "          Dropout-35                 [-1, 4096]               0\n",
            "           Linear-36                 [-1, 4096]      16,781,312\n",
            "             ReLU-37                 [-1, 4096]               0\n",
            "          Dropout-38                 [-1, 4096]               0\n",
            "           Linear-39                 [-1, 1000]       4,097,000\n",
            "================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 218.78\n",
            "Params size (MB): 527.79\n",
            "Estimated Total Size (MB): 747.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Training Loop\n",
        "# ----------------------------\n",
        "def training(model, train_dl, num_epochs):\n",
        "  # Loss Function, Optimizer and Scheduler\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "  scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
        "                                                steps_per_epoch=int(len(train_dl)),\n",
        "                                                epochs=num_epochs,\n",
        "                                                anneal_strategy='linear')\n",
        "\n",
        "  # Repeat for each epoch\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct_prediction = 0\n",
        "    total_prediction = 0\n",
        "\n",
        "    # Repeat for each batch in the training set\n",
        "    for i, data in enumerate(train_dl):\n",
        "        # Get the input features and target labels, and put them on the GPU\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Normalize the inputs\n",
        "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "        inputs = (inputs - inputs_m) / inputs_s\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Keep stats for Loss and Accuracy\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Get the predicted class with the highest score\n",
        "        _, prediction = torch.max(outputs,1)\n",
        "        # Count of predictions that matched the target label\n",
        "        correct_prediction += (prediction == labels).sum().item()\n",
        "        total_prediction += prediction.shape[0]\n",
        "\n",
        "        #if i % 10 == 0:    # print every 10 mini-batches\n",
        "        #    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
        "    \n",
        "    # Print stats at the end of the epoch\n",
        "    num_batches = len(train_dl)\n",
        "    avg_loss = running_loss / num_batches\n",
        "    acc = correct_prediction/total_prediction\n",
        "    print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n",
        "\n",
        "  print('Finished Training')\n",
        "  \n",
        "num_epochs=35   # Just for demo, adjust this higher.\n",
        "training(myModel, train_dl, num_epochs)     "
      ],
      "metadata": {
        "id": "fgXeMN0cM8VW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "2e7eec3a-02da-45a8-c7ad-a7e2bff25256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.51, Accuracy: 0.83\n",
            "Epoch: 1, Loss: 0.50, Accuracy: 0.83\n",
            "Epoch: 2, Loss: 0.50, Accuracy: 0.83\n",
            "Epoch: 3, Loss: 0.51, Accuracy: 0.83\n",
            "Epoch: 4, Loss: 0.52, Accuracy: 0.83\n",
            "Epoch: 5, Loss: 0.53, Accuracy: 0.82\n",
            "Epoch: 6, Loss: 0.51, Accuracy: 0.83\n",
            "Epoch: 7, Loss: 0.53, Accuracy: 0.82\n",
            "Epoch: 8, Loss: 0.52, Accuracy: 0.82\n",
            "Epoch: 9, Loss: 0.53, Accuracy: 0.82\n",
            "Epoch: 10, Loss: 0.52, Accuracy: 0.82\n",
            "Epoch: 11, Loss: 0.53, Accuracy: 0.82\n",
            "Epoch: 12, Loss: 0.50, Accuracy: 0.83\n",
            "Epoch: 13, Loss: 0.49, Accuracy: 0.84\n",
            "Epoch: 14, Loss: 0.49, Accuracy: 0.84\n",
            "Epoch: 15, Loss: 0.47, Accuracy: 0.84\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-d4a7580c7cf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35\u001b[0m   \u001b[0;31m# Just for demo, adjust this higher.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-d4a7580c7cf3>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, train_dl, num_epochs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Inference\n",
        "# ----------------------------\n",
        "def inference (model, val_dl):\n",
        "  correct_prediction = 0\n",
        "  total_prediction = 0\n",
        "\n",
        "  # Disable gradient updates\n",
        "  with torch.no_grad():\n",
        "    for data in val_dl:\n",
        "      # Get the input features and target labels, and put them on the GPU\n",
        "      inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "      # Normalize the inputs\n",
        "      inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "      inputs = (inputs - inputs_m) / inputs_s\n",
        "\n",
        "      # Get predictions\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # Get the predicted class with the highest score\n",
        "      _, prediction = torch.max(outputs,1)\n",
        "      # Count of predictions that matched the target label\n",
        "      correct_prediction += (prediction == labels).sum().item()\n",
        "      total_prediction += prediction.shape[0]\n",
        "    \n",
        "  acc = correct_prediction/total_prediction\n",
        "  print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')\n",
        "\n",
        "# Run inference on trained model with the validation set\n",
        "inference(myModel, val_dl)"
      ],
      "metadata": {
        "id": "OABtyrDtOMPN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c76930-fd97-4961-e0c3-b293caa150a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.83, Total items: 1746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Epochs = my_array = list(range(1, 46));\n",
        "Loss_history = [2.06, 1.64, 1.40, 1.25, 1.14, 1.06, 0.96, 0.93, 0.90, 0.87, 0.86, 0.85, 0.84, 0.81, 0.80, 0.77, 0.72, 0.70, 0.66, 0.64, 0.62, 0.60, 0.57, 0.55, 0.55, 0.55, 0.53, 0.50, 0.51, 0.51, 0.50, 0.50, 0.51, 0.52, 0.53, 0.51, 0.53, 0.52, 0.53, 0.52, 0.53, 0.50, 0.49, 0.49]\n",
        "Accu_history = [0.27, 0.44, 0.52, 0.57, 0.61, 0.64, 0.67, 0.69, 0.70, 0.71, 0.72, 0.72, 0.71, 0.72, 0.73, 0.74, 0.76, 0.77, 0.78, 0.79, 0.79, 0.79, 0.81, 0.82, 0.82, 0.82, 0.83, 0.84, 0.83, 0.83, 0.83, 0.83, 0.83, 0.83, 0.82, 0.83, 0.82, 0.82, 0.82, 0.82, 0.82, 0.83, 0.84, 0.84]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(Accu_history)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(Loss_history)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NuQzb8ZvdyM_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "791d252a-72eb-4e88-e194-54e3a4282abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhV5bn+8e+TkBCGQCDMhBmsICJIRJwVtUVF1DoUrW1tq2itQ3tsj7a/Hmtte07b03pUxDpQW61zrQNVqpXJoQKCgsokSRBIgggEAmFIIMnz+2Ov6CYG2CA7ayfr/lwXV/ea9nr2qtn3ft93DebuiIhIdKWFXYCIiIRLQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQiIhGnIJBIMbO/mNmvElx3lZmdkeyaRMKmIBARiTgFgUgTZGYtwq5Bmg8FgaScoEvmx2b2vpltN7M/mVlXM/unmVWY2XQz6xC3/ngzW2Jm5WY228wGxy0bYWbvBts9BWTV29c4M1sUbPuWmQ1LsMZzzGyhmW01s2Izu63e8hOD9ysPll8RzG9lZn8ws9VmtsXM3gzmnWpmJQ0chzOC17eZ2TNm9qiZbQWuMLNRZjYn2MfHZnaPmWXGbX+Emb1qZpvM7BMz+6mZdTOzHWaWG7fe0Wa2wcwyEvns0vwoCCRVXQicCRwGnAv8E/gp0JnYf7c3AJjZYcATwA+CZdOAf5hZZvCl+DzwV6Aj8LfgfQm2HQE8BFwN5AL3A1PNrGUC9W0HvgnkAOcA3zOz84P37RPUOymoaTiwKNju98BI4Pigpv8EahM8JucBzwT7fAyoAX4IdAKOA04Hrg1qyAamAy8DPYCBwAx3XwfMBi6Je99vAE+6++4E65BmRkEgqWqSu3/i7qXAG8A8d1/o7pXAc8CIYL2vAS+5+6vBF9nvgVbEvmhHAxnAne6+292fAebH7WMicL+7z3P3Gnd/GKgKttsnd5/t7h+4e627v08sjE4JFl8GTHf3J4L9lrn7IjNLA74D3OjupcE+33L3qgSPyRx3fz7Y5053f8fd57p7tbuvIhZkdTWMA9a5+x/cvdLdK9x9XrDsYeByADNLBy4lFpYSUQoCSVWfxL3e2cB02+B1D2B13QJ3rwWKgZ7BslLf886Kq+Ne9wFuCrpWys2sHOgVbLdPZnasmc0KulS2ANcQ+2VO8B5FDWzWiVjXVEPLElFcr4bDzOxFM1sXdBf9dwI1ALwADDGzfsRaXVvc/e2DrEmaAQWBNHVriX2hA2BmRuxLsBT4GOgZzKvTO+51MfBrd8+J+9fa3Z9IYL+PA1OBXu7eHrgPqNtPMTCggW02ApV7WbYdaB33OdKJdSvFq3+r4D8Cy4FB7t6OWNdZfA39Gyo8aFU9TaxV8A3UGog8BYE0dU8D55jZ6cFg503EunfeAuYA1cANZpZhZl8FRsVt+yBwTfDr3sysTTAInJ3AfrOBTe5eaWajiHUH1XkMOMPMLjGzFmaWa2bDg9bKQ8AdZtbDzNLN7LhgTGIFkBXsPwP4GbC/sYpsYCuwzcwOB74Xt+xFoLuZ/cDMWppZtpkdG7f8EeAKYDwKgshTEEiT5u4fEvtlO4nYL+5zgXPdfZe77wK+SuwLbxOx8YRn47ZdAFwF3ANsBgqDdRNxLXC7mVUAtxILpLr3XQOcTSyUNhEbKD4qWPwj4ANiYxWbgN8Cae6+JXjPKcRaM9uBPc4iasCPiAVQBbFQeyquhgpi3T7nAuuAAuC0uOX/JjZI/a67x3eXSQSZHkwjEk1mNhN43N2nhF2LhEtBIBJBZnYM8CqxMY6KsOuRcKlrSCRizOxhYtcY/EAhIKAWgYhI5KlFICIScU3uxlWdOnXyvn37hl2GiEiT8s4772x09/rXpgBNMAj69u3LggULwi5DRKRJMbO9niasriERkYhTEIiIRJyCQEQk4prcGEFDdu/eTUlJCZWVlWGXklRZWVnk5eWRkaHnh4jIodMsgqCkpITs7Gz69u3LnjeabD7cnbKyMkpKSujXr1/Y5YhIM9IsuoYqKyvJzc1ttiEAYGbk5uY2+1aPiDS+ZhEEQLMOgTpR+Iwi0viaRdeQiOxd4foK5hSV8ZWh3eiSnRV2ObIX67dW8uzCUnZUVe91ndMHd+WoXjmHfN8KgkOgvLycxx9/nGuvvfaAtjv77LN5/PHHyck59P/Hiixft5VJMwuZ9sHHuMOvXlrGpaN6c80pA+jWXoGQKtaW7+T+14p4Yn4xu6pr2VfDv0u7LAVBqiovL+fee+/9XBBUV1fTosXeD/G0adOSXZpE0OLSLdw9o4B/Lf2Eti1bcO2pA/jykG48Nm81j85dzePz1nDJMXlcc8oA8jq03v8bSlIUb9rBvbOLeOadYtzhopF5XHvqQHrnNv7/JwqCQ+CWW26hqKiI4cOHk5GRQVZWFh06dGD58uWsWLGC888/n+LiYiorK7nxxhuZOHEi8NntMrZt28ZZZ53FiSeeyFtvvUXPnj154YUXaNWqVcifTJqShWs2M2lmITOXryc7qwU3nj6Ib5/Ql5zWmQAc1SuH68cM4o+vFfHU/GKefLuYC4/O4+pT+tO9fer8t5aVkdasx8NWbdzO5FmFPLewlDQzvnZMr9BDucndhjo/P9/r32to2bJlDB48GIBf/GMJS9duPaT7HNKjHT8/94i9Ll+1ahXjxo1j8eLFzJ49m3POOYfFixd/eprnpk2b6NixIzt37uSYY47htddeIzc3d48gGDhwIAsWLGD48OFccskljB8/nssvv/xz+4r/rCIA81dt4u4ZBbxRsJGc1hlceWI/vnl8X9pl7f16k/rdEalkcPd2XD9mIGOP6EZa2r4DYXdNLc8tLOW+14qornEmntyfi/PzaNkivZGqTVzh+m1MnlXIC4tKyUhPa/RuOjN7x93zG1qmFkESjBo1ao9z/e+++26ee+45AIqLiykoKCA3N3ePbfr168fw4cMBGDlyJKtWrWq0eqXpcXfmrowFwJyVZeS2yeTmsYfzjeP60Lbl/v+se+S04hfnDeXa0wby0vsfs6smNcJgd3Utzy0q5drH3mVQl7ZcN2Yg44b1IL1eIOyqruWZd0q4d3YhJZt3ckSPdmS2SuNnzy/mnpmFXHNKfyaM6k1WRviB8OG6CibNLOClDz4mq0U63zmhHxNP6Z9SA/fNLgj29cu9sbRp0+bT17Nnz2b69OnMmTOH1q1bc+qppzZ4LUDLli0/fZ2ens7OnTsbpVZpWtydNwo2MmlmAfNXbaZzdkt+ds5gLju2N60zD/zPuWu7LL5zYmpdoHjtaQN56YOPuWdmATc+uYi7phdw7WkDOX94D6prnacXFHPf7CLWbqnkqF45/GL8EYw5vAsA/y4s4+4ZBdz2j6VMnl3E1Sf3P+hj80UtLt3CPTMLeXnJOtpkpnPNKQO48sR+5LZtuf+NG1mzC4IwZGdnU1HR8BP/tmzZQocOHWjdujXLly9n7ty5jVydpJLqmlr+8f5a3iveclDbLyouZ1FxOd3bZ/GL8UfwtWN6pcSv3kMpPc0Yf1QPxh3ZnVeWrOPumYX86G/vcdeMFVTtrmV9RRX5fTrwmwuHcdKgTnuMJ5w4qBMnDurE3JWxQPjVS8v44+wivjK0G5npjXfZ1Kqy7cz+cAPZWS24YcxAvnNiv0/HalKRguAQyM3N5YQTTmDo0KG0atWKrl27frps7Nix3HfffQwePJgvfelLjB49OsRKJSy7qmt59t0S7p1dxJpNO2jbssXnujsSkds2k/++4EguHNkzJfvBD6W0NOOsI7szdmg3pi9bz4Ovr6RlRhp3ThjOcf33fSeB0f1zGd0/l3dWb2LSzEJeev/jRqwc2mSmc9OZh/HN4/vSvlXq3xus2Q0WN3dR+qzNQVV1DU8vKOG+2UWUlu9kWF57rh8ziDMGd2nWZ8ZI6tFgsUgjq9xdwxNvr+G+14r4ZGsVR/fO4VcXDOXUwzorACTlKAhEDrGN26q4fMo8lq+rYFS/jtxxyXCOH9C8b4ooTVtSg8DMxgJ3AenAFHf/Tb3lvYGHgZxgnVvc/aAut3X3Zv+H1tS68aJo/dZKLpsyj5LNO/jTt/I5fXDX/W8kErKkDaObWTowGTgLGAJcamZD6q32M+Bpdx8BTADuPZh9ZWVlUVZW1qy/KOueR5CVlTrnHsue1m2pZMIDc1lbvpO/fHuUQkCajGS2CEYBhe6+EsDMngTOA5bGreNAu+B1e2DtwewoLy+PkpISNmzY8AXKTX11TyiT1FNavpPLHpxL2bZdPPKdUeT37Rh2SSIJS2YQ9ASK46ZLgGPrrXMb8C8zux5oA5zR0BuZ2URgIkDv3r0/tzwjI0NP7ZLQFG/awaUPzmXLzt088t1RHN27Q9gliRyQsB9McynwF3fPA84G/mpmn6vJ3R9w93x3z+/cuXOjFymyN6vLtvO1++dQUVnNY1ceqxCQJimZLYJSoFfcdF4wL953gbEA7j7HzLKATsD6JNYlsocNFVVs3rHrgLcr37GbG55YSFV1DY9deSxDe7ZPQnUiyZfMIJgPDDKzfsQCYAJwWb111gCnA38xs8FAFtC8O/olZRRtqLsb5Fpqag/uRIPcNpk8ftVoBndvt/+VRVJU0oLA3avN7DrgFWKnhj7k7kvM7HZggbtPBW4CHjSzHxIbOL7Cm/OpP5ISVnxSwT0zC3nx/bVktkjjiuP7HnSXzsg+HfS0L2nyknodQXBNwLR6826Ne70UOCGZNYjUWbp2K/fMKuCfi9fRKiOdq07uz1Un9adTCt4NUqQx6cpiafY+KNnC3TMLeHXpJ2S3bMH3T43dDbJjm9S9G6RIY1IQSLP17prNTJpRwKwPN9AuqwU/OGMQ3z6+H+1bp/7dIEUak4JAmp23P9rEpJmxRzd2aJ3Bj7/yJb55XB+y9/HoRpEoUxBIs+DuzCkq4+6ZBcxduYlObTP56dmH8/Vj+9AmgUc3ikSZ/kKkSXN3Xi/YyN0zCnhn9Wa6tmvJreOGcOmo3rTKbN4PbhE5VBQE0iS5OzOWrWfSzALeK9lCj/ZZ/PK8I7g4v/k9ulEk2RQE0qTU1jr/WrqOSTMLWbJ2K706tuI3Xz2Srx6dR2aLsO+YItI0KQikyfho43a+9+g7LF9XQd/c1vzvRcM4f0RPMhrxoeQizZGCQJqEwvXbuOzBuVTXOnd+bTjjhnWnhQJA5JBQEEjKW/FJBZc9OBcwnpw4msO6Zoddkkizop9UktKWfbyVCQ/MJc0UAiLJohaBpKzFpVu4/E/zaJWRzuNXjaZfpzZhlyTSLKlFICnpveJyLntwLm0yW/DUxOMUAiJJpCCQlPPums1cPmUe7Vtn8OTE0fTObR12SSLNmrqGJGXs3FXDY/NWc+f0Ajq1jT3wpUdOq7DLEmn2FAQSuu1V1fx17mqmvLGSjdt2cfyAXO64ZLge+CLSSBQEEpqtlbt55K1VTHnzI8p37OakQZ244fRBHNO3Y9iliUSKgkAa3ZYdu3no3x/x539/xNbKasYc3oXrxwxkxEE+LlJEvhgFgTSaTdt3MeWNlTwyZzXbqqr58pCuXD9mEEfmtQ+7NJFIUxBI0q2vqGTKGx/x1zmrqayu4ewju3PdaQMZ3L1d2KWJCAoCSaJ1Wyq5//UiHp+3ht01tYw/qgfXjRnIwC66OlgklSgIIm5RcTn3zCxkcemWva7TPSeLq0/uz5eHdCMtzfb7nqXlO/nj7EKenl9CjTtfHdGTa08bqIvCRFKUgiCiFqzaxN0zC3l9xQZyWmdw+uFdadHAl7zjzF+1mWsefZcvdc3mujEDOfvI7qQ3sO6ash3cO7uQv79bAsBFI/O49tSB9OqoC8JEUpmCIELcnbkrYw92f6uojNw2mdw89nC+cVwf2u7jub7VNbW89MHHTJpZyPVPLOTO6Su4bsxAzh3WgxbpaazcsI3Js4p4flEp6WnGpaN6c/UpA+ipi8FEmgRz97BrOCD5+fm+YMGCsMtoUtydNws3MmlGIW+v2kTn7JZcfXJ/Lju2N60zE/8tUFPr/HPxx9wzs/DTh8MM6dGOlxevI7NFGpeN6sPVp/SnaztdCCaSaszsHXfPb2iZWgTNmLsz+8MN3D2zgIVryunWLovbzh3ChFG9D+q5vulpxrhhPTh7aHdeXfYJk2YWMPvDDVx1Un+uPKk/nbNbJuFTiEiyJTUIzGwscBeQDkxx99/UW/5/wGnBZGugi7vnJLOmKHB3Xl36CZNmFvJB6RZ65rTiV+cP5eL8PFq2+OIPdk9LM75yRDe+ckS3Q1CtiIQtaUFgZunAZOBMoASYb2ZT3X1p3Tru/sO49a8HRiSrniiorXVeXrKOu2cUsHxdBb07tuZ3Fw7jgqP1XF8R2btktghGAYXuvhLAzJ4EzgOW7mX9S4GfJ7GeZqum1nnx/bXcM7OQgvXb6N+pDXdcchTjj+qh5/qKyH4lMwh6AsVx0yXAsQ2taGZ9gH7AzL0snwhMBOjdu/ehrbIJq66p5YVFa5k8q5CVG7czqEtb7pownHHDejR4eqeISENSZbB4AvCMu9c0tNDdHwAegNhZQ41ZWCraVV3LcwtLmDyriDWbdjC4ezv++PWj+coRiV3wJSISL5lBUAr0ipvOC+Y1ZALw/STW0mz8/Z0S7nh1BaXlOxmW157/GpfPGYO7YKYAEJGDk8wgmA8MMrN+xAJgAnBZ/ZXM7HCgAzAnibU0C/fMLOD3/1rB8F45/OqCoZx6WGcFgIh8YUkLAnevNrPrgFeInT76kLsvMbPbgQXuPjVYdQLwpDe1K9sakbtz14wC7pxewPnDe/D7i4/SILCIHDJJHSNw92nAtHrzbq03fVsya2jq3J0//GsF98wq5KKRefz2wmEaCBaRQypVBoulAe7Ob15ezv2vreTSUb349flHajBYRA45BUGKcnd++eIyHvr3R1w+uje3jx+qEBCRpFAQpCB357apS3h4zmq+fUJfbh03RIPCIpI0CoIU4+7c+sIS/jp3NRNP7s9PzjpcISAiSaVTT1LM1PfWKgREpFEpCFLIui2V/Nfzizm6dw43j1UIiEjjUBCkCHfn5r+/z66aWv5wyXCdIioijUZBkCKenF/Mays28JOzBush7yLSqBQEKaB40w5+9eJSjh+QyzdG9wm7HBGJGAVByGprnR/97T3MjN9dNEzXCohIo1MQhOzPb61i3kebuPXcIeR1aB12OSISQQqCEBWu38bvXl7O6Yd34eKReWGXIyIRpSAISXVNLTf97T1aZabzP189UqeKikhodGVxSO5/fSXvFZcz6dIRdGmXFXY5IhJhahGEYOnardw5fQXnDOvOuUf1CLscEYk4BUEj21Vdy388vYj2rTL55XlDwy5HRERdQ43trhkrWL6uginfzKdjm8ywyxERUYugMS1cs5k/zi7i4pF5nDGka9jliIgACoJGs3NXDTc9/R7d2mXxX+cOCbscEZFPqWuokfzvKx+ycuN2Hv3usbTLygi7HBGRT6lF0AjmFJXx0L8/4pvH9eHEQZ3CLkdEZA8KgiTbVlXNj595jz65rbnlrMPDLkdE5HPUNZRkv35pGaXlO/nb1cfROlOHW0RSj1oESTT7w/U88fYaJp7Un/y+HcMuR0SkQQkFgZk9a2bnmJmCI0EVlbu5+e/vM6hLW3545mFhlyMisleJfrHfC1wGFJjZb8zsS4lsZGZjzexDMys0s1v2ss4lZrbUzJaY2eMJ1pPyHnpzFZ9sreJ3Fw0jKyM97HJERPYqoU5rd58OTDez9sClweti4EHgUXffXX8bM0sHJgNnAiXAfDOb6u5L49YZBPwEOMHdN5tZly/8iVLAlh27mfLmSs4c0pURvTuEXY6IyD4l3NVjZrnAFcCVwELgLuBo4NW9bDIKKHT3le6+C3gSOK/eOlcBk919M4C7rz+g6lPUlDdXUlFZzQ/PUJeQiKS+RMcIngPeAFoD57r7eHd/yt2vB9ruZbOeQHHcdEkwL95hwGFm9m8zm2tmY/ey/4lmtsDMFmzYsCGRkkOzafsuHnrzI84+shtDerQLuxwRkf1K9HzGu919VkML3D3/C+5/EHAqkAe8bmZHunt5vX08ADwAkJ+f719gf0l3/+tF7Nhdww/UGhCRJiLRrqEhZpZTN2FmHczs2v1sUwr0ipvOC+bFKwGmuvtud/8IWEEsGJqkDRVVPPLWasYf1YPDumaHXY6ISEISDYKr4n+lB336V+1nm/nAIDPrZ2aZwARgar11nifWGsDMOhHrKlqZYE0p577XiqiqruGG05tslolIBCUaBOkW91Dd4Iygfd5M392rgeuAV4BlwNPuvsTMbjez8cFqrwBlZrYUmAX82N3LDvRDpIJPtlby6NzVXDAijwGd9zZsIiKSehIdI3gZeMrM7g+mrw7m7ZO7TwOm1Zt3a9xrB/4j+Nek3TurkOpa50a1BkSkiUk0CG4m9uX/vWD6VWBKUipqgkrLd/LE28VcPDKP3rmtwy5HROSAJHpBWS3wx+Cf1DN5ViGOc92YgWGXIiJywBIKguAK4P8BhgBZdfPdvX+S6moyijft4On5xVw6qjd5HdQaEJGmJ9HB4j8Taw1UA6cBjwCPJquopuTuGQWkpRnfP02tARFpmhINglbuPgMwd1/t7rcB5ySvrKZhTdkOnl1YyteP7U239ln730BEJAUlOlhcFdyCusDMriN2YVjkz5F8bN5qAK4+eUDIlYiIHLxEWwQ3ErvP0A3ASOBy4FvJKqopqNxdw9MLijlzcFe1BkSkSdtviyC4eOxr7v4jYBvw7aRX1QS8vHgdm3fs5vLRfcIuRUTkC9lvi8Dda4ATG6GWJuXRuavpm9ua4wfkhl2KiMgXkugYwUIzmwr8DdheN9Pdn01KVSlu+bqtLFi9mf939mDS0mz/G4iIpLBEgyALKAPGxM1zIJJB8NjcNWS2SOOikXlhlyIi8oUlemWxxgUC26uqeW5hKeOO7E6HNvu8756ISJOQ6JXFfybWAtiDu3/nkFeU4l5YtJZtVdV8fXTvsEsRETkkEu0aejHudRZwAbD20JeT2tydx+at5vBu2Ryth9KLSDORaNfQ3+OnzewJ4M2kVJTCFhWXs2TtVn55/lDiHs8gItKkJXpBWX2DgC6HspCm4LF5a2iTmc4FI3qGXYqIyCGT6BhBBXuOEawj9oyCyCjfsYt/vLeWC0fm0bZloj1qIiKpL9Guocg/if3v75ZSVV3L5cfqSmIRaV4S6hoyswvMrH3cdI6ZnZ+8slJL3SDxiN45DOnRLuxyREQOqUTHCH7u7lvqJty9HPh5ckpKPXNWlrFyw3a1BkSkWUo0CBpaLzId5Y/NXUP7VhmcM6x72KWIiBxyiQbBAjO7w8wGBP/uAN5JZmGpYn1FJa8sWcfFI/PIykgPuxwRkUMu0SC4HtgFPAU8CVQC309WUalk+tL1VNc6lxzTK+xSRESSItGzhrYDtyS5lpT0VtFGurZryaAukX8gm4g0U4meNfSqmeXETXcws1eSV1ZqcHfmrtzEcf1zdSWxiDRbiXYNdQrOFALA3TcTgSuLC9dvY+O2Ko7Tw2dEpBlLNAhqzezT222aWV8auBtpfWY21sw+NLNCM/tc15KZXWFmG8xsUfDvykQLbwxvFZUBcPyATiFXIiKSPImeAvr/gDfN7DXAgJOAifvaIHjW8WTgTKAEmG9mU919ab1Vn3L36w6s7MYxp6iMnjmt6NWxddiliIgkTUItAnd/GcgHPgSeAG4Cdu5ns1FAobuvdPddxM42Ou8L1NqoamuduR+VqVtIRJq9RG86dyVwI5AHLAJGA3PY89GV9fUEiuOmS4BjG1jvQjM7GVgB/NDdi+uvYGYTCVogvXs3zgNhlq3bSvmO3Xo4vYg0e4mOEdwIHAOsdvfTgBFA+b43Scg/gL7uPgx4FXi4oZXc/QF3z3f3/M6dOx+C3e7fnGB8QC0CEWnuEg2CSnevBDCzlu6+HPjSfrYpBeKvwsoL5n3K3cvcvSqYnAKMTLCepJu7soy+ua3p3r5V2KWIiCRVokFQElxH8Dzwqpm9AKzezzbzgUFm1s/MMoEJwNT4Fcws/uY944FlCdaTVNU1tcxbuYnjdLaQiERAolcWXxC8vM3MZgHtgZf3s021mV0HvAKkAw+5+xIzux1Y4O5TgRvMbDxQDWwCrji4j3FoLVm7lYqqanULiUgkHPAdRN39tQNYdxowrd68W+Ne/wT4yYHWkGxzVsbGB0b37xhyJSIiyXewzyxu1uYUlTGoS1u6ZGeFXYqISNIpCOrZXVPL/FWb1C0kIpGhIKjn/ZJyduyq4bj+CgIRiQYFQT111w8cqyAQkYhQENTzVlEZg7u3o2ObzLBLERFpFAqCOFXVNbyzerO6hUQkUhQEcRauKaequlYDxSISKQqCOG8VlZFmMKqfrh8QkehQEMSZW1TG0J7tad8qI+xSREQajYIgsHNXDQuLNT4gItGjIAgsWL2J3TWu8QERiRwFQWBOURkt0oxj+mp8QESiRUEQmLOyjGF57WnT8oDvwyci0qQpCIBtVdW8X7KF4/X8ARGJIAUBMH/VJmpqNT4gItGkIAAKPqkAYGjP9iFXIiLS+BQEQOnmnWS3bKHrB0QkkhQEQGn5Tnp20EPqRSSaFARAaXklPXMUBCISTQoCoHTzDnooCEQkoiIfBBWVu9laWa2uIRGJrMgHQWn5TgB1DYlIZEU+CNbWBYFaBCISUZEPgtLNahGISLRFPghKyneSmZ5G57Ytwy5FRCQUkQ+CteWVdM/JIi3Nwi5FRCQUSQ0CMxtrZh+aWaGZ3bKP9S40Mzez/GTW05DSzTvULSQikZa0IDCzdGAycBYwBLjUzIY0sF42cCMwL1m17Etp+U5dQyAikZbMFsEooNDdV7r7LuBJ4LwG1vsl8FugMom1NGhXdS3rK6rUIhCRSEtmEPQEiuOmS4J5nzKzo4Fe7v7Svt7IzCaa2QIzW7Bhw4ZDVuC6LZW469RREYm20AaLzSwNuAO4aX/ruvsD7p7v7vmdO3c+ZDWUlO8AdOqoiERbMoOgFOgVN50XzKuTDQwFZpvZKmA0MLUxB4x1DYGISHKDYD4wyMz6mVkmMAGYWrfQ3be4ey32E1UAAAhtSURBVCd37+vufYG5wHh3X5DEmvawtjw2LNE9J6uxdikiknKSFgTuXg1cB7wCLAOedvclZna7mY1P1n4PRGn5Drpkt6Rli/SwSxERCU2LZL65u08DptWbd+te1j01mbU0RKeOiohE/Mri0s16MpmISGSDoLbWWbulkjy1CEQk4iIbBBu3V7GrulYtAhGJvMgGQd2poz3aKwhEJNoiGwR1p46qRSAiURfZICitu6pYQSAiERfdINi8k+yWLWiXlRF2KSIioYpuEJTr1FEREYh0EFTqHkMiIkQ5CDbvUItARISIBkFF5W62Vlbr9hIiIkQ0CErLdftpEZE6kQyCtXVBoK4hEZFoBkHdVcW6z5CISESDoKR8J5npaXRq2zLsUkREQhfJIFhbXkn3nCzS0izsUkREQhfJICjdvEMDxSIigWgGgZ5MJiLyqcgFwa7qWtZXVKlFICISiFwQrNtSibtOHRURqRO5ICgJbj+tU0dFRGIiFwSfPplMQSAiAkQwCOqeTNY9JyvkSkREUkPkgqC0fAddslvSskV62KWIiKSECAaBHkgjIhIvqUFgZmPN7EMzKzSzWxpYfo2ZfWBmi8zsTTMbksx6IDZGoPEBEZHPJC0IzCwdmAycBQwBLm3gi/5xdz/S3YcDvwPuSFY9ALW1ztotlTpjSEQkTjJbBKOAQndf6e67gCeB8+JXcPetcZNtAE9iPWzcXsWu6lp1DYmIxGmRxPfuCRTHTZcAx9Zfycy+D/wHkAmMSWI9n5062l5BICJSJ/TBYnef7O4DgJuBnzW0jplNNLMFZrZgw4YNB72vulNH1SIQEflMMoOgFOgVN50XzNubJ4HzG1rg7g+4e76753fu3PngCwquKlYQiIh8JplBMB8YZGb9zCwTmABMjV/BzAbFTZ4DFCSxHko37yQ7qwXtsjKSuRsRkSYlaWME7l5tZtcBrwDpwEPuvsTMbgcWuPtU4DozOwPYDWwGvpWseiC4hkBnDImI7CGZg8W4+zRgWr15t8a9vjGZ+6+vtLxSQSAiUk/og8WNqXTzDo0PiIjUE5kgqKjczdbKarUIRETqiUwQlJbr9tMiIg2JTBCsDYJAXUMiInuKTBDUXVWs+wyJiOwpMkHQtV0WXx7SlU5tW4ZdiohISknq6aOp5MtHdOPLR3QLuwwRkZQTmRaBiIg0TEEgIhJxCgIRkYhTEIiIRJyCQEQk4hQEIiIRpyAQEYk4BYGISMSZu4ddwwExsw3A6oPcvBOw8RCW05zo2Oydjs3e6dg0LBWPSx93b/BZv00uCL4IM1vg7vlh15GKdGz2Tsdm73RsGtbUjou6hkREIk5BICIScVELggfCLiCF6djsnY7N3unYNKxJHZdIjRGIiMjnRa1FICIi9SgIREQiLjJBYGZjzexDMys0s1vCridMZvaQma03s8Vx8zqa2atmVhD8b4cwawyDmfUys1lmttTMlpjZjcF8HRuzLDN728zeC47NL4L5/cxsXvB39ZSZZYZda1jMLN3MFprZi8F0kzk2kQgCM0sHJgNnAUOAS81sSLhVheovwNh6824BZrj7IGBGMB011cBN7j4EGA18P/jvRMcGqoAx7n4UMBwYa2ajgd8C/+fuA4HNwHdDrDFsNwLL4qabzLGJRBAAo4BCd1/p7ruAJ4HzQq4pNO7+OrCp3uzzgIeD1w8D5zdqUSnA3T9293eD1xXE/qh7omODx2wLJjOCfw6MAZ4J5kfy2ACYWR5wDjAlmDaa0LGJShD0BIrjpkuCefKZru7+cfB6HdA1zGLCZmZ9gRHAPHRsgE+7PhYB64FXgSKg3N2rg1Wi/Hd1J/CfQG0wnUsTOjZRCQI5AB47pziy5xWbWVvg78AP3H1r/LIoHxt3r3H34UAesVb24SGXlBLMbByw3t3fCbuWg9Ui7AIaSSnQK246L5gnn/nEzLq7+8dm1p3Yr77IMbMMYiHwmLs/G8zWsYnj7uVmNgs4DsgxsxbBL9+o/l2dAIw3s7OBLKAdcBdN6NhEpUUwHxgUjOJnAhOAqSHXlGqmAt8KXn8LeCHEWkIR9Ov+CVjm7nfELdKxMetsZjnB61bAmcTGUGYBFwWrRfLYuPtP3D3P3fsS+26Z6e5fpwkdm8hcWRyk9Z1AOvCQu/865JJCY2ZPAKcSu1XuJ8DPgeeBp4HexG7zfYm71x9QbtbM7ETgDeADPuvr/SmxcYKoH5thxAY804n9gHza3W83s/7ETr7oCCwELnf3qvAqDZeZnQr8yN3HNaVjE5kgEBGRhkWla0hERPZCQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQijcjMTq27O6VIqlAQiIhEnIJApAFmdnlw//1FZnZ/cMO1bWb2f8H9+GeYWedg3eFmNtfM3jez5+qeV2BmA81senAP/3fNbEDw9m3N7BkzW25mjwVXNIuERkEgUo+ZDQa+BpwQ3GStBvg60AZY4O5HAK8RuyIb4BHgZncfRuyq5Lr5jwGTg3v4Hw/U3cF0BPADYs/G6E/sXjUioYnKTedEDsTpwEhgfvBjvRWxG83VAk8F6zwKPGtm7YEcd38tmP8w8DczywZ6uvtzAO5eCRC839vuXhJMLwL6Am8m/2OJNExBIPJ5Bjzs7j/ZY6bZf9Vb72DvzxJ/v5ka9HcoIVPXkMjnzQAuMrMu8Okzi/sQ+3upu5vkZcCb7r4F2GxmJwXzvwG8FjzhrMTMzg/eo6WZtW7UTyGSIP0SEanH3Zea2c+Af5lZGrAb+D6wHRgVLFtPbBwBYrcYvi/4ol8JfDuY/w3gfjO7PXiPixvxY4gkTHcfFUmQmW1z97Zh1yFyqKlrSEQk4tQiEBGJOLUIREQiTkEgIhJxCgIRkYhTEIiIRJyCQEQk4v4/px9JkKfYnosAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4DMHf9Agkm0Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}